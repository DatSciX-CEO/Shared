You are a coding assistant tasked with developing the complete Minimum Viable Product (MVP) for 'Agent Utis', an AI agent application for an eDiscovery vendor similar to Consilio (providing end-to-end eDiscovery services, document review, legal tech) and LOD (Lawyers on Demand, offering flexible legal talent and interim experts). The app focuses on expertise in utilization across all aspects, such as analyzing expert utilization rates, billable hours, cost efficiency, predictive spend, and resource optimization in legal and eDiscovery contexts. For the MVP, enable loading a CSV file via Streamlit, process the data with AI agents, allow interactive expert consultations, and provide additional analysis. The app must run entirely locally with no cloud dependencies, using Ollama for Mistral:7b as the LLM. Use best practices throughout: clean code structure, error handling, modularity, documentation, data privacy (local processing only), efficient resource use, testing considerations, type hints, comments, logging, and unit tests where applicable. Be flexible in producing the best code, files, folders, and project structureâ€”e.g., include additional files like utils.py, tests/, requirements.txt if beneficial. If any aspect is not explicitly prompted, infer and implement best practices to ensure a fully working, robust MVP. Follow the provided list of tasks sequentially to structure development, but adapt as needed for optimal implementation. Output all code, scripts, and instructions in a structured format (e.g., dictionary of filenames to content) for easy setup and execution.

To ensure accurate structure, code, files, and folders according to official documentation, reference and incorporate guidelines from the following sources:

Google ADK documentation: https://google.github.io/adk-docs/ (official docs site) and https://github.com/google/adk-python (GitHub repo for installation, examples, and API reference).
Ollama documentation: https://github.com/ollama/ollama (GitHub repo with setup and usage) and https://github.com/ollama/ollama/tree/main/docs (detailed docs folder), plus Python integration at https://github.com/ollama/ollama-python.
Streamlit documentation: https://docs.streamlit.io/ (official docs, including get-started guide at https://docs.streamlit.io/get-started and API reference at https://docs.streamlit.io/develop/api-reference).
LiteLLM documentation (for LLM integration if needed): https://github.com/BerriAI/litellm (GitHub repo) and https://docs.litellm.ai/ (official docs site).
NumPy polyfit documentation (for forecasting in Spend Predictor): https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html (official NumPy reference).
Requirements:

App Name: Agent Utis
Core Functionality: Streamlit UI for CSV upload (e.g., columns: expert_name, project, billable_hours, total_hours, cost, date). Process data with hierarchical agents. Interactive chat for queries (e.g., 'Analyze Q2 utilization' or 'Predict next quarter spend'). Display results, charts, and analysis.
Frameworks/Tools: Google ADK (AI Agents via pip install google-adk), Ollama (local LLMs with mistral:7b), Streamlit (UI), pandas (data handling), and supporting libs (e.g., matplotlib for charts, numpy for calculations, litellm for LLM integration if needed). All local.
Agents Structure: Hierarchical with top-level 'Finance Director' orchestrating sub-agents: Data Analyst (CSV processing), Utilization Expert (metrics like utilization_rate = billable_hours / total_hours, ROI), Spend Predictor (forecasting via simple regression, e.g., numpy.polyfit), Compliance Checker (align with legal best practices, hardcoded benchmarks like 70-80% utilization target). Use Ollama Mistral:7b as LLM backend in ADK, configured via LiteLLM or custom provider.
Integration: Configure ADK with Ollama (custom LLM integration using LiteLLM if supported). Define tools (e.g., pandas functions, custom calc). Handle queries via Finance Director delegation.
Best Practices: Modular code (e.g., separate files: setup.sh, agents.py, main.py, utils.py). Error handling (invalid CSV, queries). Session state in Streamlit for history/data. Prompts for agents to ensure accuracy, factual domain-specific analysis. Include example CSV generation in a data/ folder. README with setup/run instructions. Generate requirements.txt. Add any other processes like virtual env setup, Docker if enhances local run.
Subtasks: Follow this list of tasks to structure development, but integrate them into the full MVP output:
Task: Setup Project Environment Description: Create a setup script or instructions to initialize the local development environment for the Agent Utis MVP. This includes installing required packages like Google ADK (Agent Development Kit) for AI agents, Ollama for local LLMs using mistral:7b, Streamlit for the UI, and any supporting libraries such as pandas for CSV processing. Ensure everything runs locally without cloud dependencies. Provide the code as a Python script or bash commands that the user can run to set up the project directory, virtual environment, and pull the Mistral model via Ollama. Requirements:
Use pip for installations since ADK is available via pip (adk-python).
Install Ollama and run 'ollama pull mistral:7b'.
Include dependencies: streamlit, pandas, and any ADK requirements.
Create a basic project structure: main.py for Streamlit, agents.py for agent definitions. Output Format: Provide the response as a complete bash script followed by Python code if needed, ensuring it's executable locally.
Task: Define Hierarchical AI Agents Description: Using Google ADK, define a hierarchical agent structure for Agent Utis, an AI agent app for eDiscovery vendors similar to Consilio (providing end-to-end eDiscovery services, document review, legal tech) and LOD (Lawyers on Demand, offering flexible legal talent and interim experts). Focus on utilization expertise in all aspects, such as analyzing expert utilization rates, billable hours, cost efficiency, predictive spend, and resource optimization in legal and eDiscovery contexts. The top-level agent is the 'Finance Director' which orchestrates sub-agents. Sub-agents include: Data Analyst (for processing CSV data), Utilization Expert (for calculating metrics like utilization rates, ROI on experts), Spend Predictor (for forecasting legal spend based on historical data), and Compliance Checker (for ensuring analysis aligns with legal spend management best practices). Integrate with Ollama using Mistral:7b as the local LLM backend. Ensure agents can process CSV data loaded from Streamlit. Requirements:
Import from adk (Agent Development Kit).
Configure ADK to use Ollama's Mistral:7b as the LLM provider (reference ADK documentation for custom LLM integration).
Define tools for agents: e.g., pandas for data loading/analysis, custom functions for utilization calculations (e.g., utilization_rate = billable_hours / total_hours).
Hierarchical setup: Finance Director delegates tasks to sub-agents and synthesizes results.
Handle data privacy locally since it runs only on the user's machine. Output Format: Provide the Python code as a module (e.g., agents.py) that defines the agents, tools, and orchestration logic. Include example usage.
Task: Build Streamlit UI for MVP Description: Create the Streamlit application for Agent Utis MVP. The UI should allow users to upload a CSV file (e.g., containing columns like expert_name, project, billable_hours, total_hours, cost, date for legal/eDiscovery utilization data). Once uploaded, process the data with the hierarchical agents defined in ADK. Provide an interactive chat interface where users can query the agents as experts (e.g., 'Analyze utilization for Q2' or 'Predict spend for next quarter'). Display results, charts (using matplotlib or Streamlit's built-in), and any additional analysis for utilization expertise. Ensure integration with the agents using Ollama Mistral:7b locally. Requirements:
Use Streamlit components: file_uploader for CSV, chat_input for interaction, display dataframes/charts.
On upload, load CSV with pandas and pass to agents.
Invoke the Finance Director agent to handle queries, which delegates to sub-agents.
Run entirely locally; no external APIs.
Include error handling for invalid CSV or queries. Output Format: Provide the complete Python code for main.py that runs the Streamlit app. Use st.session_state to maintain conversation history and data.
Task: Generate Example CSV and Test Data Description: To ensure a full working MVP, generate an example CSV file structure and sample data for testing Agent Utis. The CSV should represent utilization data for eDiscovery experts, similar to services from Consilio and LOD, including columns for expert utilization analysis (e.g., expert_id, name, role, project_id, start_date, end_date, billable_hours, total_hours, hourly_rate, total_cost, utilization_rate). Provide sample rows for 10-15 entries. Also, include test queries and expected outputs for validation. Requirements:
CSV format compatible with pandas.
Data reflective of eDiscovery/legal spend: e.g., roles like 'Document Reviewer', 'Legal Analyst'; projects like 'Litigation Support'.
Utilization metrics: Pre-compute or let agents calculate (e.g., utilization_rate = billable_hours / total_hours * 100). Output Format: Provide the CSV content as a string that can be saved to a file, plus a list of 5 test queries with expected analysis summaries.
Task: Additional Analysis and Expertise Prompts Description: Create embedded prompts for the agents to ensure extremely accurate analysis in utilization expertise. For the Finance Director: Synthesize sub-agent outputs into comprehensive reports. For Utilization Expert: Calculate key metrics like average utilization, over/under-utilization flags, cost per utilized hour. For Spend Predictor: Use simple linear regression (via statsmodels or sklearn, but since local and basic, use numpy/polyfit) for forecasting based on historical data. Ensure prompts guide the Mistral:7b LLM to be precise, factual, and domain-specific to eDiscovery/legal spend. Requirements:
Prompts in string format for Google ADK agent configurations.
Incorporate best practices from legal spend analysis: e.g., identify cost savings opportunities, benchmark against industry standards (hardcode averages like 70-80% utilization target).
Handle edge cases: missing data, low sample size. Output Format: Provide a dictionary of prompts, keyed by agent name, each as a detailed system prompt string for the LLM.
Task: Integration and Run Instructions Description: Provide a final integration script or README content to tie everything together for the MVP. Include commands to run Ollama server, start Streamlit, and any troubleshooting for local setup. Ensure the app is fully functional for loading CSV, processing with agents, and interactive expertise on utilization in eDiscovery contexts. Requirements:
Steps: 1. Start Ollama: ollama serve & ollama run mistral:7b. 2. Run Streamlit: streamlit run main.py.
Verify ADK integration with Ollama.
Note: All local, no internet needed after setup. Output Format: Provide the content as a Markdown README.md string.
System Prompt: You are an expert developer building a local AI agent app for eDiscovery utilization analysis. Prioritize accuracy, completeness, and best practices: use type hints, comments, logging, unit tests if applicable. Synthesize all components into a working MVP. For agents, embed detailed system prompts for precision (e.g., Finance Director: 'Synthesize sub-agent outputs into reports on utilization, cost savings, benchmarks.'). Handle edge cases like missing data. Be flexible: if a better structure or additional files improve the project, include them.